{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the first line of code below we are writing a path to a .md or markdown file. We then create two constants which are defined by all capital letters. These variables cannot be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'excel', 'mysql', 'python', 'statistics'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}\n",
    "REQUIRED_SKILLS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a function called load_file by using def. In this function, we're reading a file, turning all of the text to lowercase and then splitting all the words up into a list. By deafult the split function will seperate text with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below passes the path we created above into the load_file function to create a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* Why is a `set` created?\n",
    "* How are we populating the set\n",
    "* Why would it be necessary to create a `punctuation` set?\n",
    "* What does subtracting from the set do?\n",
    "* * Refer to the `resume = resume - punctuation` line\n",
    "* What does `\\n` do in a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets are like lists, but unordered so the items have no index. We use a set here beacuse we can loop through the set items using a for loop. We are populating the set with every token or text speperated by spaces from our word_list using the .add function.\n",
    "\n",
    "We create a punctuation set to identify all stop words and special characters. Substracting the punctuation from the resume, removes these stop words and special characters from the resume  set.\n",
    "\n",
    "Note that the use of \\n in a string creates a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'the', 'aws', 'learning,', 'tables', 'with', 'social', 'microsoft', 'sets', 'sql,', 'statistics', 'to', 'education', 'javascript,', 'n.', 'mysql', 'visualizations', 'api', 'open-source', 'data', 'r,', 'mining,', 'tableau,', 'skills', 'cloud', 'css,', 'bootstrap,', 'contributing', 'graduate', 'creating', 'apps', 'hadoop,', 'basic', 'working', 'from', 'pivot', 'front-end', 'html/css,', 'html,', 'forecasting', 'interactions,', 'mining', 'hadoop', 'vba', 'leaflet.js', 'using', '##', 'software', 'python', 'scripts', 'frank', 'd3,', 'stein', 'intelligence', 'statistics,', 'python,', 'analyze', 'big', 'learning', 'machine', 'analytics', 'excel.', 'boot', 'interests', 'algorithms', 'files', 'media', 'd3', 'web', 'pandas', 'git/github', 'developing', 'in', 'performing', 'excel,', 'and', 'designing', 'modeling', 'tableau', 'apis.', 'mongodb', 'business', 'camp', 'writing', 'databases', 'visualization', 'experience', 'advanced'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'the', 'aws', 'learning,', 'tables', 'with', 'social', 'microsoft', 'sets', 'sql,', 'open-source', 'statistics', 'to', 'education', 'javascript,', 'n.', 'mysql', 'visualizations', 'api', 'data', 'r,', 'mining,', 'tableau,', 'skills', 'cloud', 'css,', 'bootstrap,', 'contributing', 'graduate', 'creating', 'apps', 'hadoop,', 'basic', 'working', 'from', 'pivot', 'front-end', 'html/css,', 'html,', 'forecasting', 'interactions,', 'mining', 'hadoop', 'vba', 'leaflet.js', 'using', '##', 'software', 'python', 'scripts', 'frank', 'd3,', 'stein', 'intelligence', 'statistics,', 'python,', 'analyze', 'big', 'learning', 'machine', 'analytics', 'excel.', 'boot', 'interests', 'algorithms', 'files', 'media', 'd3', 'web', 'pandas', 'git/github', 'developing', 'in', 'performing', 'excel,', 'and', 'designing', 'modeling', 'tableau', 'apis.', 'mongodb', 'business', 'camp', 'writing', 'databases', 'visualization', 'experience', 'advanced'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "resume\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first two paragraphs below, we use a set intersection determine which required and desired skill this resume has.\n",
    "\n",
    "Next, we do some charachter cleaning. Unlike word cleaning, charachter cleaning removes special charachters from words.\n",
    "\n",
    "After cleaning our words with some automated solutions, we notice there are still words thta we don't want in our word_list. So we create a variable called stop_words with additional words that we want to remove. Then we overwrite our word_list excluding these stop_words using a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'statistics', 'mysql', 'python'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Collections.counter is optional, but explain the difference between the `for loop` and using `Counter`\n",
    "\n",
    "Below we create a dictionary named `word_count`. The keys for the dictionary are our elements in `word_list` and the values are set to 0. \n",
    "\n",
    "The for loop that we created looks at every word in our `word_list` and if those words mathc a word in our word_count dictionary, it adds 1 to the value of that respective key. \n",
    "\n",
    "You can also use counter here. Note that counter creates a series, while the for loop appends a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. Which column was sorted and how? How was the top ten selected? Does that explain the significance of `[:10]`?\n",
    "\n",
    "In the for loop below, the first thing that happens is the the dictionary is sorted. By deafult the dictionary will be sorted on the values.\n",
    "\n",
    "Then we take words from the beginning to position 10 and print their key and value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n",
      "Token: mining               Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
